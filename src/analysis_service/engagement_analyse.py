import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import IsolationForest

class EngagementAnalyzer():

  def __init__(self, student_logs_df: pd.DataFrame):
    self.df = student_logs_df
    self.df['timestamp'] = pd.to_datetime(self.df['timestamp'])
    self.engagement_metrics = {}
    self.student_risk = {}

  def calculate_engagement_metrics(self):
    self.calculate_active_metrics()
    self.calculate_learning_patterns()
    self.calculate_temp_patterns()
    self.calculate_learning_efficiency()
    self.calculate_risk_scores()

  def calculate_active_metrics(self):
    student_activity = self.df.groupby('student_id').agg({
        'timestamp': ['min', 'max', 'count'],
        'time_spent_on_mat': 'sum',
        'time_spent_on_question': 'sum',
        'attempts': 'sum',
        'correctness': 'mean'
    }).round(2)

    student_activity.columns = ['first_activity', 'last_activity', 'total_events', 
                          'total_material_time', 'total_question_time', 
                          'total_attempts', 'avg_correctness']

    student_activity['total_learning_time'] = (
            student_activity['total_material_time'] + student_activity['total_question_time']
        )
    student_activity['activity_duration_days'] = (
        (student_activity['last_activity'] - student_activity['first_activity']).dt.days + 1
    )

    student_activity['events_per_day'] = (
    student_activity['total_events'] / student_activity['activity_duration_days']).round(2)

    activity_numeric = student_activity.drop(['first_activity', 'last_activity'], axis=1) #—É–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã, —Ç.–∫. –≤—Ä–µ–º—è –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è—Ö

    self.engagement_metrics['activity'] = activity_numeric
    self.engagement_metrics['activity_dates'] = student_activity[['first_activity', 'last_activity']]

  def calculate_learning_patterns(self):
    learning_patterns = {}

    for student_id in self.df['student_id'].unique():
      student_data = self.df[self.df['student_id'] == student_id]

      total_material_time = student_data['time_spent_on_mat'].sum()
      total_question_time = student_data['time_spent_on_question'].sum()

      material_engagement = (total_material_time / total_question_time if total_question_time > 0 else 0) #–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –º–∞—Ç–µ—Ä–∏–∞–ª / –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ —Ç–µ—Å—Ç

      retry_rate = (student_data['attempts'] > 1).mean() #—Å—Ä –∫–æ–ª-–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –Ω–∞ —Ç–µ—Å—Ç

      passive_score = self.calculate_passive_score(student_data, 300, 0.5, 100, 0.1)
      effort_eff = self.calculate_effort_efficiency(student_data)


      learning_patterns[student_id] = {
          '–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç_–≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç–∏_–º–∞—Ç–µ—Ä–∏–∞–ª–∞': round(material_engagement, 3),
          '–ß–∞—Å—Ç–æ—Ç–∞ –ø–æ–ø—ã—Ç–æ–∫': round(retry_rate, 3),
          '–°—Ä –∫–æ–ª-–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –Ω–∞ –≤–æ–ø—Ä–æ—Å': student_data['attempts'].mean().round(2),
          'consistency_score': self._calculate_consistency(student_data),
          '–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –º–∞—Ç–µ—Ä–∏–∞–ª–∞ –Ω–∞ –º–∞—Ç–µ—Ä–∏–∞–ª + —Ç–µ—Å—Ç': total_material_time / (total_material_time + total_question_time)
          if (total_material_time + total_question_time) > 0 else 0,
          '–ò–Ω–¥–∏–∫–∞—Ç–æ—Ä –ø–∞—Å—Å–∏–≤–Ω–æ–≥–æ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è': round(passive_score, 3),
          '—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —É—Å–∏–ª–∏–π': round(effort_eff, 3)
      }

      self.engagement_metrics['learning_patterns'] = pd.DataFrame.from_dict(
          learning_patterns, orient='index'
      )

  def calculate_temp_patterns(self):
    temp_patterns = {}

    for student_id in self.df['student_id'].unique():
      student_data = self.df[self.df['student_id'] == student_id]

      student_data['hour'] = student_data['timestamp'].dt.hour
      student_data['day_of_week'] = student_data['timestamp'].dt.dayofweek
      student_data['is_weekend'] = student_data['day_of_week'].isin([5, 6])

      hour_counts = student_data['hour'].value_counts()
      preferred_hour = hour_counts.index[0] if len(hour_counts) > 0 else 12

      day_distribution = student_data['day_of_week'].value_counts(normalize=True) #–í—ã—á–∏—Å–ª—è–µ—Ç –¥–æ–ª—é –∫–∞–∂–¥–æ–≥–æ –¥–Ω—è –∫–æ–≥–¥–∞ —Å—Ç—É–¥–µ–Ω—Ç —É—á–∏–ª—Å—è
      regularity_score = day_distribution.std() if len(day_distribution) > 1 else 0.5 #–≤—ã—á–∏—Å–ª—è–µ—Ç std, –µ—Å–ª–∏ —Ä–µ–≥—É–ª—è—Ä–Ω–æ –∑–∞–Ω–∏–º–∞–ª—Å—è(—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ), —Ç–æ –∫–æ—ç—Ñ—Ñ –±—É–¥–µ—Ç –Ω–∏–∑–∫–∏–π 


      temp_patterns['–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã'] = {
          '–°–∞–º—ã–π —á–∞—Å—Ç—ã–µ —á–∞—Å—ã': preferred_hour,
          '–∫–æ—ç—Ñ—Ñ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –Ω–∞ –≤—ã—Ö–æ–¥–Ω—ã—Ö': student_data['is_weekend'].mean().round(3),
          '—É—Ä–æ–≤–µ–Ω–∏ —Ä–µ–≥—É–ª—è—Ä–Ω–æ—Å—Ç–∏': 1 - round(regularity_score, 3),
          '—Å–∞–º—ã–π –∞–∫—Ç–∏–≤–Ω—ã–π –¥–µ–Ω—å': student_data['day_of_week'].mode()[0] if len(student_data) > 0 else 0,
          '—Å—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Å–µ—Å—Å–∏–∏': self._calculate_avg_session_length(student_data),
          '–î–∏—Å–ø–µ—Ä—Å–∏—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏': student_data['hour'].std() if len(student_data) > 1 else 0
      }

      self.engagement_metrics['temp_patterns'] = pd.DataFrame.from_dict(
            temp_patterns, orient='index'
        )
      
  def calculate_learning_efficiency(self):
    efficiency_metrics = {}

    for student_id in self.df['student_id'].unique():
      student_data = self.df[self.df['student_id'] == student_id]

      avg_correctness = student_data['correctness'].mean()
      total_learning_time = (
          student_data['time_spent_on_mat'].sum() +
          student_data['time_spent_on_question'].sum()
      )

      efficiency = avg_correctness / (total_learning_time / 3600) if total_learning_time > 0 else 0
      progress_score = self.calculate_learning_progress(student_data)
      retention = self.calculate_retention_rate(student_data)
      stability = self.calculate_stability_score(student_data)

      efficiency_metrics[student_id] = {
          '—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è': round(efficiency, 4),
          '–∫–æ—ç—Ñ—Ñ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞': progress_score,
          'knowledge_retention': retention,
          '—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ –≤—Ä–µ–º–µ–Ω–∏': round(avg_correctness / (total_learning_time / 60), 4)
          if total_learning_time > 0 else 0,
          '—Ä–µ–≥—É–ª—è—Ä–Ω–æ—Å—Ç—å –∑–∞–Ω—è—Ç–∏–π': round(stability, 3)
      }

    self.engagement_metrics['efficiency'] = pd.DataFrame.from_dict(
        efficiency_metrics, orient='index'
    )

  def calculate_risk_scores(self):
    try:
      key_metrics_df = self.extract_key_metrics_for_risk()
      if key_metrics_df.empty or len(key_metrics_df) < 3:
            print("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–∏—Å–∫–æ–≤")
            key_metrics_df['risk_flag'] = 1
            key_metrics_df['risk_score'] = 0
            self.engagement_metrics['risk_assessment'] = key_metrics_df
            self.risk_students = pd.DataFrame()
            return
      key_metrics_df = key_metrics_df.fillna(0)
      scaler = StandardScaler()
      scaled = scaler.fit_transform(key_metrics_df)

      contamination = min(0.3, max(0.1, 0.5 / len(key_metrics_df)))
      iso = IsolationForest(contamination=contamination, random_state=42, n_estimators=50)
      risk_flags = iso.fit_predict(scaled)
      risk_scores = iso.decision_function(scaled)

      key_metrics_df['risk_flag'] = risk_flags
      key_metrics_df['risk_score'] = risk_scores

      self.engagement_metrics['risk_assessment'] = key_metrics_df
      self.risk_students = key_metrics_df[key_metrics_df['risk_flag'] == -1]

      print(f"–ê–Ω–∞–ª–∏–∑ —Ä–∏—Å–∫–æ–≤ –∑–∞–≤–µ—Ä—à—ë–Ω. –°—Ç—É–¥–µ–Ω—Ç–æ–≤ –≤ –≥—Ä—É–ø–ø–µ —Ä–∏—Å–∫–∞: {len(self.risk_students)}")

    except Exception as e:
      print(f"–û—à–∏–±–∫–∞ –≤ –∞–Ω–∞–ª–∏–∑–µ —Ä–∏—Å–∫–æ–≤: {e}")
      dummy = pd.DataFrame(index=self.engagement_metrics['activity'].index)
      dummy['risk_flag'] = 1
      dummy['risk_score'] = 0
      self.engagement_metrics['risk_assessment'] = dummy
      self.risk_students = pd.DataFrame()


  def extract_key_metrics_for_risk(self) -> pd.DataFrame:
    act = self.engagement_metrics['activity'][['avg_correctness', 'events_per_day']]
    eff = self.engagement_metrics['efficiency'][['–∫–æ—ç—Ñ—Ñ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞', '—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è', 'performance_stability']]
    pat = self.engagement_metrics['learning_patterns'][
        ['–ß–∞—Å—Ç–æ—Ç–∞ –ø–æ–ø—ã—Ç–æ–∫', '–ò–Ω–¥–∏–∫–∞—Ç–æ—Ä –ø–∞—Å—Å–∏–≤–Ω–æ–≥–æ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è', '—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —É—Å–∏–ª–∏–π']
    ]
    return pd.concat([act, eff, pat], axis=1).select_dtypes(include=[np.number])


  def calculate_passive_score(self, student_data: pd.DataFrame, time_threshold: int = 300, score_threshold: float = 0.5, time_difference: int = 100, score_differnce: float = 0.1) -> float:
    avg_time_material = student_data['time_spent_on_mat'].mean()
    avg_correct = student_data['correctness'].mean()

    if avg_time_material > time_threshold and avg_correct < score_threshold:
      return 0.9
    elif avg_time_material > time_threshold - time_difference and avg_correct < score_threshold + score_differnce:
      return 0.6
    else:
      return 0.1

  def calculate_effort_efficiency(self, student_data: pd.DataFrame) -> float:
    total_time_q = student_data['time_spent_on_question'].sum()
    total_attempts = student_data['attempts'].sum()
    if total_attempts == 0:
        return 0.0
    efficiency = total_time_q / total_attempts  # —Å–µ–∫—É–Ω–¥ –Ω–∞ –ø–æ–ø—ã—Ç–∫—É
    return 1 / (1 + efficiency / 60)

  def calculate_stability_score(self, student_data: pd.DataFrame) -> float:
    if len(student_data) < 2:
        return 0.5
    std = student_data['correctness'].std()
    return max(0.0, 1 - std)

  def _calculate_retention_rate(self, student_data: pd.DataFrame) -> float:
    return student_data['correctness'].mean() if len(student_data) > 0 else 0.5

  def get_student_engagement_summary(self, student_id: str):
    summary = {}
    for metric_type, df in self.engagement_metrics.items():
        if metric_type not in ['activity_dates'] and student_id in df.index:
            summary[metric_type] = df.loc[student_id].to_dict()
    return summary if summary else None



class EngagementVisualizer:
    def __init__(self, engagement_analyzer):
        self.analyzer = engagement_analyzer
        self.metrics = engagement_analyzer.engagement_metrics
    
    def create_comprehensive_dashboard(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–π –¥–∞—à–±–æ—Ä–¥–∞ –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç–∏"""
        fig = plt.figure(figsize=(20, 15))
        
        # 1. –û–ë–ó–û–†–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê
        self._plot_overview_stats(fig, 231)
        
        # 2. –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ê–ö–¢–ò–í–ù–û–°–¢–ò
        self._plot_activity_distribution(fig, 232)
        
        # 3. –í–†–ï–ú–ï–ù–ù–´–ï –ü–ê–¢–¢–ï–†–ù–´
        self._plot_temporal_patterns(fig, 233)
        
        # 4. –≠–§–§–ï–ö–¢–ò–í–ù–û–°–¢–¨ –û–ë–£–ß–ï–ù–ò–Ø
        self._plot_learning_efficiency(fig, 234)
        
        # 5. –°–¢–£–î–ï–ù–¢–´ –ì–†–£–ü–ü–´ –†–ò–°–ö–ê
        self._plot_risk_analysis(fig, 235)
        
        # 6. –ö–û–†–†–ï–õ–Ø–¶–ò–ò –ú–ï–¢–†–ò–ö
        self._plot_correlation_heatmap(fig, 236)
        
        plt.tight_layout()
        return fig
    
    def _plot_overview_stats(self, fig, position):
        ax = fig.add_subplot(position)
        
        total_students = len(self.metrics['activity'])
        active_students = len(self.metrics['activity'][
            self.metrics['activity']['events_per_day'] > 0.5
        ])
        risk_students = len(self.analyzer.risk_students)
        
        stats_data = [total_students, active_students, risk_students]
        stats_labels = ['–í—Å–µ–≥–æ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤', '–ê–∫—Ç–∏–≤–Ω—ã–µ', '–ì—Ä—É–ø–ø–∞ —Ä–∏—Å–∫–∞']
        colors = ['lightblue', 'lightgreen', 'lightcoral']
        
        bars = ax.bar(stats_labels, stats_data, color=colors, alpha=0.7)
        ax.set_title('–û–±–∑–æ—Ä–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç–∏')
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
        for bar, value in zip(bars, stats_data):
            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, 
                   f'{value}', ha='center', va='bottom')
    
    def _plot_activity_distribution(self, fig, position):
        ax = fig.add_subplot(position)
        
        events_per_day = self.metrics['activity']['events_per_day'].dropna()
        
        ax.hist(events_per_day, bins=20, alpha=0.7, color='skyblue', edgecolor='black')
        ax.axvline(events_per_day.mean(), color='red', linestyle='--', 
                  label=f'–°—Ä–µ–¥–Ω–µ–µ: {events_per_day.mean():.2f}')
        
        ax.set_xlabel('–°–æ–±—ã—Ç–∏–π –≤ –¥–µ–Ω—å')
        ax.set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤')
        ax.set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏')
        ax.legend()
    
    def _plot_temporal_patterns(self, fig, position):
        ax = fig.add_subplot(position)
        
        # –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ —á–∞—Å–∞–º
        hour_distribution = self.metrics['temporal_patterns']['preferred_study_hour'].value_counts().sort_index()
        
        ax.bar(hour_distribution.index, hour_distribution.values, 
               color='orange', alpha=0.7)
        ax.set_xlabel('–ß–∞—Å –¥–Ω—è')
        ax.set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤')
        ax.set_title('–ü—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è')
        ax.set_xticks(range(0, 24, 2))
    
    def _plot_learning_efficiency(self, fig, position):
        ax = fig.add_subplot(position)
        
        efficiency = self.metrics['efficiency']['learning_efficiency'].dropna()
        correctness = self.metrics['activity']['avg_correctness'].dropna()
        
        scatter = ax.scatter(efficiency, correctness, alpha=0.6, 
                           c=self.metrics['activity']['total_learning_time'], 
                           cmap='viridis', s=50)
        
        ax.set_xlabel('–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è')
        ax.set_ylabel('–°—Ä–µ–¥–Ω—è—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å')
        ax.set_title('–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å vs –ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å')
        plt.colorbar(scatter, ax=ax, label='–û–±—â–µ–µ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è')
    
    def _plot_risk_analysis(self, fig, position):
        ax = fig.add_subplot(position)
        
        if not self.analyzer.risk_students.empty:
            risk_factors = self.analyzer.risk_students.select_dtypes(include=[np.number]).mean()
            top_risk_factors = risk_factors.nlargest(5)
            
            ax.barh(range(len(top_risk_factors)), top_risk_factors.values, 
                   color='red', alpha=0.6)
            ax.set_yticks(range(len(top_risk_factors)))
            ax.set_yticklabels([self._format_metric_name(name) for name in top_risk_factors.index])
            ax.set_title('–¢–æ–ø —Ñ–∞–∫—Ç–æ—Ä—ã —Ä–∏—Å–∫–∞')
        else:
            ax.text(0.5, 0.5, '–ù–µ—Ç —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –≥—Ä—É–ø–ø—ã —Ä–∏—Å–∫–∞', 
                   ha='center', va='center', transform=ax.transAxes)
            ax.set_title('–ê–Ω–∞–ª–∏–∑ —Ä–∏—Å–∫–æ–≤')
    
    def _plot_correlation_heatmap(self, fig, position):
        ax = fig.add_subplot(position)
        
        combined_metrics = self.analyzer._combine_all_metrics()
        numeric_columns = combined_metrics.select_dtypes(include=[np.number]).columns
        
        # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –æ—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
        selected_metrics = [col for col in numeric_columns if any(x in col for x in 
                            ['events_per_day', 'correctness', 'efficiency', 'engagement', 'risk_score'])]
        
        if len(selected_metrics) > 1:
            correlation_matrix = combined_metrics[selected_metrics].corr()
            sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, 
                       ax=ax, fmt='.2f')
            ax.set_title('–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –º–µ—Ç—Ä–∏–∫ –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç–∏')
        else:
            ax.text(0.5, 0.5, '–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö\n–¥–ª—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞', 
                   ha='center', va='center', transform=ax.transAxes)
    
    def _format_metric_name(self, name):
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–π –º–µ—Ç—Ä–∏–∫ –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏"""
        name_parts = name.split('_')
        return ' '.join(name_parts[-2:]).title()


def create_test_student_logs(num_students=50, num_days=30):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ –ª–æ–≥–æ–≤ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤"""
    
    # –ë–∞–∑–æ–≤—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    start_date = datetime(2024, 1, 1)
    student_ids = [f"student_{i:03d}" for i in range(1, num_students + 1)]
    material_ids = [f"material_{i:03d}" for i in range(1, 21)]
    question_ids = [f"question_{i:03d}" for i in range(1, 101)]
    distractors = ['A', 'B', 'C', 'D', 'conceptual_error', 'calculation_error', 'misunderstanding']
    
    logs = []
    
    for student_id in student_ids:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Å—Ç—É–¥–µ–Ω—Ç–∞ (–¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ä–∞–∑–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤)
        student_type = np.random.choice(['active_high', 'active_medium', 'active_low', 'irregular', 'dropout'], 
                                      p=[0.3, 0.3, 0.2, 0.15, 0.05])
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ª–æ–≥–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ —Å—Ç—É–¥–µ–Ω—Ç–∞
        if student_type == 'active_high':
            num_sessions = np.random.randint(20, 30)
            correctness_range = (0.7, 0.95)
            time_on_material_range = (300, 1200)  # 5-20 –º–∏–Ω—É—Ç
        elif student_type == 'active_medium':
            num_sessions = np.random.randint(15, 25)
            correctness_range = (0.5, 0.8)
            time_on_material_range = (180, 600)   # 3-10 –º–∏–Ω—É—Ç
        elif student_type == 'active_low':
            num_sessions = np.random.randint(8, 15)
            correctness_range = (0.3, 0.6)
            time_on_material_range = (60, 300)    # 1-5 –º–∏–Ω—É—Ç
        elif student_type == 'irregular':
            num_sessions = np.random.randint(5, 12)
            correctness_range = (0.2, 0.7)
            time_on_material_range = (30, 400)    # 0.5-6 –º–∏–Ω—É—Ç
        else:  # dropout
            num_sessions = np.random.randint(1, 5)
            correctness_range = (0.1, 0.4)
            time_on_material_range = (10, 120)    # –º–∞–ª–æ –≤—Ä–µ–º–µ–Ω–∏
            
        # –°–æ–∑–¥–∞–µ–º —Å–µ—Å—Å–∏–∏ –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç–∞
        for session in range(num_sessions):
            # –°–ª—É—á–∞–π–Ω–∞—è –¥–∞—Ç–∞ –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –ø–µ—Ä–∏–æ–¥–∞
            days_offset = np.random.randint(0, num_days)
            session_date = start_date + timedelta(days=days_offset)
            
            # –í—Ä–µ–º—è —Å—É—Ç–æ–∫ (–ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –ø–æ —Ç–∏–ø–∞–º)
            if student_type in ['active_high', 'active_medium']:
                hour = np.random.normal(19, 3)  # –≤–µ—á–µ—Ä–Ω–∏–µ
            else:
                hour = np.random.uniform(9, 23)  # —Å–ª—É—á–∞–π–Ω—ã–µ
            
            hour = max(8, min(23, int(hour)))
            minute = np.random.randint(0, 60)
            
            session_time = session_date.replace(hour=hour, minute=minute)
            
            # 1-5 –¥–µ–π—Å—Ç–≤–∏–π –≤ —Å–µ—Å—Å–∏–∏
            num_actions = np.random.randint(1, 6)
            
            for action in range(num_actions):
                material_id = np.random.choice(material_ids)
                question_id = np.random.choice(question_ids)
                
                # –í—Ä–µ–º—è –Ω–∞ –º–∞—Ç–µ—Ä–∏–∞–ª (—Å–µ–∫—É–Ω–¥—ã)
                time_on_material = np.random.randint(time_on_material_range[0], time_on_material_range[1])
                
                # –ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞
                base_correctness = np.random.uniform(correctness_range[0], correctness_range[1])
                
                # –í–ª–∏—è–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –º–∞—Ç–µ—Ä–∏–∞–ª –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å
                material_effect = min(0.3, time_on_material / 4000)
                final_correctness = min(0.95, base_correctness + material_effect)
                
                is_correct = np.random.random() < final_correctness
                
                # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫
                if is_correct:
                    attempts = np.random.randint(1, 3)
                else:
                    attempts = np.random.randint(2, 5)
                
                # –í—Ä–µ–º—è –Ω–∞ –≤–æ–ø—Ä–æ—Å
                base_time = np.random.randint(30, 300)
                # –ß–µ–º –±–æ–ª—å—à–µ –ø–æ–ø—ã—Ç–æ–∫, —Ç–µ–º –±–æ–ª—å—à–µ –æ–±—â–µ–µ –≤—Ä–µ–º—è
                time_on_question = base_time * attempts * np.random.uniform(0.8, 1.2)
                
                # –î–∏—Å—Ç—Ä–∞–∫—Ç–æ—Ä (—Ç–æ–ª—å–∫–æ –¥–ª—è –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤)
                selected_distractor = None if is_correct else np.random.choice(distractors)
                
                # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å –ª–æ–≥–∞
                log_entry = {
                    'student_id': student_id,
                    'material_id': material_id,
                    'question_id': question_id,
                    'timestamp': session_time + timedelta(minutes=action*5),
                    'time_spent_on_mat': max(10, int(time_on_material * np.random.uniform(0.7, 1.3))),
                    'correctness': is_correct,
                    'attempts': attempts,
                    'time_spent_on_question': max(15, int(time_on_question)),
                    'selected_distractor': selected_distractor,
                    'student_type': student_type  # –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
                }
                
                logs.append(log_entry)
    
    return pd.DataFrame(logs)

# # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç
# print("üé≤ –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ student_logs_df...")
# student_logs_df = create_test_student_logs(num_students=50, num_days=30)

# print("‚úÖ –î–∞—Ç–∞—Å–µ—Ç —Å–æ–∑–¥–∞–Ω!")
# print(f"üìä –†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞: {student_logs_df.shape}")
# print(f"üë• –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Ç—É–¥–µ–Ω—Ç–æ–≤: {student_logs_df['student_id'].nunique()}")
# print(f"üìÖ –ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö: {student_logs_df['timestamp'].min()} - {student_logs_df['timestamp'].max()}")
# print(f"üìù –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(student_logs_df)}")

# # –ü–æ–∫–∞–∂–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫
# print("\n–ü–µ—Ä–≤—ã–µ 5 –∑–∞–ø–∏—Å–µ–π:")
# print(student_logs_df.head().to_string())

# # –ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
# print("\nüìà –ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
# print(f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ –º–∞—Ç–µ—Ä–∏–∞–ª: {student_logs_df['time_spent_on_mat'].mean():.1f} —Å–µ–∫")
# print(f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ –≤–æ–ø—Ä–æ—Å: {student_logs_df['time_spent_on_question'].mean():.1f} —Å–µ–∫")
# print(f"–û–±—â–∞—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å: {student_logs_df['correctness'].mean():.2%}")
# print(f"–°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫: {student_logs_df['attempts'].mean():.2f}")

# # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º —Å—Ç—É–¥–µ–Ω—Ç–æ–≤
# print("\nüéØ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –ø–æ —Ç–∏–ø–∞–º:")
# print(student_logs_df.groupby('student_type')['student_id'].nunique())

# # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏ —Ä–∞—Å—á–µ—Ç
# engagement_analyzer = EngagementAnalyzer(student_logs_df)
# engagement_metrics = engagement_analyzer.calculate_comprehensive_metrics()

# # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
# visualizer = EngagementVisualizer(engagement_analyzer)
# dashboard = visualizer.create_comprehensive_dashboard()
# plt.show()

# # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
# print(f"üéØ –í—Å–µ–≥–æ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤: {len(engagement_metrics['activity'])}")
# print(f"‚ö†Ô∏è  –°—Ç—É–¥–µ–Ω—Ç–æ–≤ –≤ –≥—Ä—É–ø–ø–µ —Ä–∏—Å–∫–∞: {len(engagement_analyzer.risk_students)}")
# print(f"üìà –°—Ä–µ–¥–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {engagement_metrics['activity']['events_per_day'].mean():.2f} —Å–æ–±—ã—Ç–∏–π/–¥–µ–Ω—å")

# # –°—Ç—É–¥–µ–Ω—Ç—ã –¥–ª—è –æ—Å–æ–±–æ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è
# if not engagement_analyzer.risk_students.empty:
#     print("\nüî¥ –°—Ç—É–¥–µ–Ω—Ç—ã –≥—Ä—É–ø–ø—ã —Ä–∏—Å–∫–∞:")
#     print(engagement_analyzer.risk_students.index.tolist())